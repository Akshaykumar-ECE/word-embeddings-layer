# word-embeddings-layer
word embedding implementation in Python for text processing and analysis
Word embedding = converting words into vectors so that similar words are close in meaning and can be used in machine learning models.
Representing the word into the dense vector
Common algorithms to generate word embeddings include Word2Vec, GloVe, and FastText. For example, in Word2Vec, the words “king” and “queen” will have vectors close to each other, while “apple” will be far away.

